# -*- coding: utf-8 -*-
"""Indian_liver_patient.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hrXfcYgNh-P69O_JYjs88nNMjb1RkqDV

## Datasets Source
This dataset was from the UCI ML Repository:
https://archive.ics.uci.edu/ml/datasets/ILPD+(Indian+Liver+Patient+Dataset)

## Dataset Information
This training dataset contains 467 records, including 333 liver patient records and 134 non liver patient records. The data set was collected from north east of Andhra Pradesh, India. Label field is a class label used to divide into groups(liver patient or not). Any patient whose age exceeded 89 is listed as being of age "90".

## Attribute Information:
1. Age: Age of the patient (年齡)
2. Gender: Gender of the patient (性別)
3. TB: Total Bilirubin (總膽紅素)
4. DB: Direct Bilirubin (直接型膽紅素/結合型膽紅素)
5. Alkphos: Alkaline Phosphotase (鹼性磷酸酶)
6. Sgpt: Alamine Aminotransferase (麩胺酸丙酮酸轉氨基酶/GPT)
7. Sgot: Aspartate Aminotransferase (麩胺酸苯醋酸轉氨基酶/GOT)
8. TP: Total Protiens (總蛋白)
9. ALB: Albumin (白蛋白)
10. A/G Ratio: Albumin and Globulin Ratio (白蛋白/球蛋白比值)
11. Label: used to split the data into two sets

## Additional information
[如何解讀肝功能檢驗報告]
https://www.jah.org.tw/form/index-1.asp?m=3&m1=8&m2=366&gp=361&id=522

### Download the training set
"""

# 從Google drive上下載壓縮檔
!gdown --id 1Y2gYY8XUWgcIA_GbytBuXoRkLlAWxnAF

!unzip project1_indian_liver_patient.zip
# if seeing the message: "replace project1_test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename:"
# you may enter "A"

# Commented out IPython magic to ensure Python compatibility.
#匯入所需模組
# %matplotlib inline
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

#讀取訓練集檔案
df = pd.read_csv('project1_train.csv')
df.columns

#顯示前五筆資料來測試訓練集是否讀取成功
df.head()

"""### The stage is yours"""

#檢查資料類型,並提供缺失值詳細信息
df.info()

print(df['Albumin_and_Globulin_Ratio'].mean())

#利用Albumin_and_Globulin_Ratio的平均值,將缺失值補上
print(df['Albumin_and_Globulin_Ratio'].mean())
df['Albumin_and_Globulin_Ratio']=df['Albumin_and_Globulin_Ratio'].fillna(0.929)

#檢查資料集中是否還存在缺失值
df.info()

sns.countplot(x="Label",data=df)

sns.countplot(x="Label",hue="Gender",data=df)

sns.displot(df['Age'],kde=False)

plt.figure(figsize=(20,10))
sns.countplot(x='Age',data=df,order=df['Age'].value_counts().index)

sns.scatterplot(x="Label", y="Albumin", data=df)

sns.scatterplot(x="Label", y="Albumin_and_Globulin_Ratio", data=df)

sns.scatterplot(x="Albumin", y="Albumin_and_Globulin_Ratio", data=df)

#查看完整相關性表格
df.corr().style.background_gradient(cmap='viridis')

df['Gender'].value_counts()

#將訓練集中Gender裡Male及Female進行轉換(Male->0,Female->1)
categories = {"Male":0, "Female":1}
df['Gender'] = df['Gender'].replace(categories)

#進行切割資料前的處理
Y = df["Label"].values
X = df.drop(labels = ["Label","Gender"], axis=1)

#標準化
from keras.utils import normalize
X = normalize(X, axis=1)
X.info

#切割資料
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

#RANDOM FOREST
from sklearn.ensemble import RandomForestClassifier
model_1 = RandomForestClassifier(n_estimators = 25, random_state = 42)

model_1.fit(X_train, y_train)

features_list = list(X.columns)
feature_imp = pd.Series(model_1.feature_importances_, index=features_list).sort_values(ascending=False)
print(feature_imp)

prediction_test_1 = model_1.predict(X_test)

(unique, counts) = np.unique(prediction_test_1, return_counts=True)
print(unique, counts)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, prediction_test_1)
print(cm)

print("With Lung disease = ", cm[1,1] / (cm[0,1]+cm[1,1]))
print("No disease = ", cm[0,0] / (cm[0,0]+cm[1,0]))

from sklearn import metrics
print ("Accuracy = ", metrics.accuracy_score(y_test, prediction_test_1))

from sklearn.utils import resample
print(df['Label'].value_counts())

df_majority = df[df['Label'] == 1]
df_minority = df[df['Label'] == 0]

df_minority_upsampled = resample(df_minority,
                  replace=True,
                  n_samples=333,
                  random_state=42)

df_upsampled = pd.concat([df_majority, df_minority_upsampled])
print(df_upsampled['Label'].value_counts())

#進行資料切割前的處理
Y_upsampled = df_upsampled["Label"].values
X_upsampled = df_upsampled.drop(labels = ["Label","Gender"], axis=1)
#標準化
from keras.utils import normalize
X_upsampled = normalize(X_upsampled, axis=1)
X_upsampled.info

#切割資料
from sklearn.model_selection import train_test_split
X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(X_upsampled,
                                                Y_upsampled,
                                                test_size=0.2,
                                                random_state=20)

#RANDOM FOREST
from sklearn.ensemble import RandomForestClassifier
model_2 = RandomForestClassifier(n_estimators = 25, random_state = 42)

model_2.fit(X_train_upsampled, y_train_upsampled)
prediction_test_2 = model_2.predict(X_test_upsampled)

print ("Accuracy = ", metrics.accuracy_score(y_test_upsampled, prediction_test_2))

cm_upsampled = confusion_matrix(y_test_upsampled, prediction_test_2)
print(cm_upsampled)

print("With Lung disease =  = ", cm_upsampled[1,1] / (cm_upsampled[0,1]+cm_upsampled[1,1]))
print("No lung disease = ",  cm_upsampled[0,0] / (cm_upsampled[0,0]+cm_upsampled[1,0]))

from sklearn.metrics import roc_auc_score
print("ROC_AUC score for balanced data using upsampling is:")
print(roc_auc_score(y_test_upsampled, prediction_test_2))


from yellowbrick.classifier import ROCAUC

roc_auc=ROCAUC(model_2)
roc_auc.fit(X_train_upsampled, y_train_upsampled)
roc_auc.score(X_test_upsampled, y_test_upsampled)
roc_auc.show()

"""### Make prediction and submission file"""

#利用測試集預測並將結果以csv檔輸出
x_test = pd.read_csv('project1_test.csv')
categories = {"Male":0, "Female":1}
x_test['Gender'] = x_test['Gender'].replace(categories)
x_test=x_test.drop(['Gender'],axis=1)
x_test = normalize(x_test, axis=1)
df_submit = pd.DataFrame([], columns=['Id', 'Category'])
df_submit['Id'] = [f'{i:03d}' for i in range(len(x_test))]
df_submit['Category'] = model_2.predict(x_test)
df_submit.to_csv('submission.csv', index=None)

df_submit.to_csv('submission.csv', index=None)